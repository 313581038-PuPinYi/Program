{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def read_trainData(filename):\n",
    "    # 讀入檔案\n",
    "    raw_data = pd.read_csv(filename, \n",
    "                            header=None, \n",
    "                            encoding='utf8')\n",
    "\n",
    "    # 去除標頭和多餘直行\n",
    "    row, col = raw_data.shape\n",
    "    raw_data  = raw_data.iloc[1:row, 3:col]              \n",
    "\n",
    "    # 去除多餘空格\n",
    "    raw_data = raw_data.replace(r'\\s+', '', regex=True)  \n",
    "\n",
    "    # 將特殊符號替換為 0\n",
    "    special_chars = ['#', '*', 'x', 'A']  # 定義需要替換的特殊符號\n",
    "    raw_data.replace(special_chars, 0.0, inplace=True)\n",
    "\n",
    "    # 轉換成numpy & 浮點數型別\n",
    "    data = raw_data.values \n",
    "    data = data.astype('float')\n",
    "\n",
    "    X, Y = [], []\n",
    "\n",
    "    # 起始值:0 , 結束值: data.shape[0], 每次增加步長: 18*20\n",
    "    for month in range(0, data.shape[0], 18*20):\n",
    "        # month: 第幾月份\n",
    "        days = np.vsplit(data[month:month+18*20], 20) # shape: (18*24) *20 -> 數據按照行數分割成 20 天\n",
    "        concat = np.concatenate(days, axis=1) # shape: (18 feature, 480(days*hr)) -> 將20天數據沿著水平方向拼接\n",
    "        # print(concat.shape)\n",
    "        for hour in range(0, concat.shape[1]):\n",
    "            # hour: 第幾小時    \n",
    "            features = concat[:, hour:hour+1].flatten() # 選取從第 j 小時到第 j+N 小時的數據\n",
    "            features = np.append(features, [1])   # 特徵向量的末尾添加一個 1，這是為了引入偏置項 w0     \n",
    "            # print(features)\n",
    "            X.append(features)\n",
    "            Y.append([concat[9, hour]])             # 第 9 行（是feature PM2.5），目標值\n",
    "\n",
    "        # if month == 0:  \n",
    "        #     print(f\"np.array(X): {np.array(X)}\")\n",
    "        #     # print(X)\n",
    "\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    print(f\"X.shape: {X.shape}\")\n",
    "    print(f\"Y.shape: {Y.shape}\")\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_testData(filename):\n",
    "    # 讀入檔案\n",
    "    raw_data = pd.read_csv(filename, \n",
    "                            header=None, \n",
    "                            encoding='utf8')\n",
    "\n",
    "    # 去除標頭和多餘直行\n",
    "    row, col = raw_data.shape\n",
    "    raw_data  = raw_data.iloc[:, 2:col]              \n",
    "\n",
    "    # 去除多餘空格\n",
    "    raw_data = raw_data.replace(r'\\s+', '', regex=True)  \n",
    "\n",
    "    # 將特殊符號替換為 0\n",
    "    special_chars = ['#', '*', 'x', 'A','WIND_DIR+D2070EC']  # 定義需要替換的特殊符號\n",
    "    raw_data.replace(special_chars, 0.0, inplace=True)\n",
    "    \n",
    "    # 轉換成numpy & 浮點數型別\n",
    "    data = raw_data.values \n",
    "    data = data.astype('float')\n",
    "    # print(data.shape)\n",
    "    # 每個月剩餘的天數\n",
    "    test_X  = []\n",
    "\n",
    "    for month in range(0, data.shape[0], 18*1):\n",
    "        # i : 第幾個月\n",
    "        day = data[month:month+18*1]             # shape: (18 feature, (1day*9hr))\n",
    "\n",
    "        for hour in range(0, day.shape[1]):\n",
    "            features = day[:, hour:hour+1].flatten() \n",
    "            # print(features)\n",
    "            features = np.append(features, [1])\n",
    "            test_X.append(features)\n",
    "\n",
    "        # if month == 0:  \n",
    "        #     print(f\"np.array(X): {np.array(test_X).shape}\")\n",
    "\n",
    "\n",
    "    test_X = np.array(test_X)    \n",
    "\n",
    "    print(f\"test_X.shape: {test_X.shape}\")\n",
    "    \n",
    "    return test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_X.shape: (2196, 19)\n",
      "[ 18.2    2.41   0.77   0.29   6.8   30.9   37.7    4.1   53.    35.\n",
      "   0.    84.     2.8    2.7  140.   120.     0.4    0.5    1.  ]\n"
     ]
    }
   ],
   "source": [
    "test_X = read_testData('input_data/test.csv')\n",
    "print(test_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_Regression(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def train(self, train_X, train_Y):\n",
    "        '''\n",
    "        普通最小二乘法（Ordinary Least Squares, OLS），\n",
    "        它是解線性回歸問題的常用方法。\n",
    "        最小二乘法的目標是最小化預測值與真實值之間的誤差平方和，\n",
    "        並通過矩陣運算來求解最優的權重 W\n",
    "            np.matmul() 是 NumPy 中用來進行矩陣乘法（Matrix Multiplication）的函數\n",
    "        \n",
    "            W = (X^T * X)^-1 *  X^T y\n",
    "        '''\n",
    "        \n",
    "        # X^T X: 計算 X 的轉置與 X 的矩陣乘積\n",
    "        X_transpose_X = np.matmul(np.transpose(train_X), train_X)\n",
    "        # (X^T X)^-1: 計算 (X^T X) 的逆矩陣\n",
    "        X_transpose_X_inv = np.linalg.inv(X_transpose_X)\n",
    "        # X^T y: 計算 X 的轉置與 y 的矩陣乘積\n",
    "        X_transpose_Y = np.matmul(np.transpose(train_X), train_Y)\n",
    "        # W = (X^T X)^-1 X^T y: 計算權重 W\n",
    "        W = np.matmul(X_transpose_X_inv, X_transpose_Y)\n",
    "        # 保存計算得到的 W，方便後續使用進行預測\n",
    "        self.W = W\n",
    "        \n",
    "    def predict(self, test_X):\n",
    "        '''\n",
    "            predict_Y = X*W\n",
    "        '''\n",
    "        predict_Y = np.matmul(test_X, self.W)\n",
    "        return predict_Y \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(predict_Y, real_Y):\n",
    "    N = len(predict_Y)  # 樣本數量\n",
    "    loss = np.sqrt(np.sum((predict_Y - real_Y)**2) / N)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_RMSE(valid_loss, train_loss, filename):\n",
    "    # assert len(train_set_loss) == len(valid_loss)\n",
    "    length = len(train_loss)\n",
    "    plt.figure(figsize = (12, 8))\n",
    "    plt.xticks(range(1, length + 1))\n",
    "    plt.plot(range(1, length+1), train_loss, 'b', label = 'train loss')\n",
    "    plt.plot(range(1, length+1), valid_loss, 'r', label = 'test loss')\n",
    "    plt.legend()\n",
    "    plt.xlabel('N')\n",
    "    plt.ylabel('RMSE loss')\n",
    "    plt.show()\n",
    "    plt.savefig(filename + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Write(answer):\n",
    "    with open(\"resultA.csv\", \"w\", newline='') as f:\n",
    "        w = csv.writer(f)\n",
    "        title = ['index','answer']\n",
    "        w.writerow(title) \n",
    "        for i in range(244):\n",
    "            content = ['index_'+str(i),answer[i][0]]\n",
    "            w.writerow(content) \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(data, del_features):\n",
    "    features = ['AMB', 'CH4', 'CO', 'NMHC', 'NO', 'NO2', 'NOx', 'O3', 'PM10', 'PM2.5', 'RAINFALL', 'RH', 'SO2', 'THC', 'WD_HR', 'WIND_DIR', 'WIND_SPEED', 'WS_HR']\n",
    "    del_pos = []\n",
    "    for i in del_features:\n",
    "        for j in range(len(features)):\n",
    "            if(i == features[j]):\n",
    "                del_pos.append(j)\n",
    "    return np.delete(data, del_pos, 1)\n",
    "\n",
    "# Pearson product-moment correlation coefficient\n",
    "# X: feature\tY: PM2.5\n",
    "def Pearson(X, Y):\n",
    "    N = len(X)\n",
    "    mu_X = np.sum(X)/N\n",
    "    mu_Y = np.sum(Y)/N\n",
    "\n",
    "    Deno = 0\n",
    "    for i in range(N):\n",
    "        Deno += (X[i]-mu_X)*(Y[i]-mu_Y)\n",
    "\n",
    "    sigma_X = 0\n",
    "    sigma_Y = 0\n",
    "    for i in range(N):\n",
    "        sigma_X += (X[i]-mu_X)**2\n",
    "        sigma_Y += (Y[i]-mu_Y)**2\n",
    "    sigma_X = np.sqrt(sigma_X)\n",
    "    sigma_Y = np.sqrt(sigma_Y)\n",
    "\n",
    "    return Deno/(sigma_X*sigma_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Write_Ret(features, numbers):\n",
    "    with open('Relation/feature.txt', \"w\", newline='') as f:\n",
    "        for i in range(len(numbers)):\n",
    "           f.write('{} Pearson number: {}\\n'.format(features[i], numbers[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_relation(train_X, train_Y, features):\n",
    "    Ret_Pearson = []\n",
    "    Ret_feature = []\n",
    "    N = len(features)\n",
    "    length = len(train_X)\n",
    "    X = np.hsplit(train_X, len(train_X[0]))\n",
    "    Y = train_Y.flatten('F')\n",
    "    for i in range(N):\n",
    "        filename = 'Relation/{}-relation.png'.format(features[i])\n",
    "        plt.figure(figsize = (12, 8))\n",
    "        plt.xticks(range(1, length+1))\n",
    "        plt.plot(range(1, length+1), X[i].flatten('F'), 'b', label = features[i])\n",
    "        plt.plot(range(1, length+1), Y, 'r', label = 'PM2.5 Next hour')\n",
    "        plt.legend()\n",
    "        plt.xlabel('N')\n",
    "        plt.savefig(filename)\n",
    "        plt.show()\n",
    "        Pearson_number = Pearson(X[i], Y)\n",
    "        Ret_Pearson.append(Pearson_number)\n",
    "        Ret_feature.append(features[i])\n",
    "        print('{} Pearson number: {}'.format(features[i], Pearson_number))\n",
    "    \n",
    "    Write_Ret(Ret_feature, Ret_Pearson)\n",
    "    return Ret_Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (5760, 19)\n",
      "Y.shape: (5760, 1)\n",
      "test_X.shape: (2196, 19)\n",
      "4.25775371871331e-14\n",
      "4.2873102710161814e-14\n"
     ]
    }
   ],
   "source": [
    "attrs = ['AMB', 'CH4', 'CO', 'NMHC', 'NO', 'NO2',\n",
    "        'NOx', 'O3', 'PM10', 'PM2.5', 'RAINFALL', 'RH',\n",
    "        'SO2', 'THC', 'WD_HR', 'WIND_DIR', 'WIND_SPEED', 'WS_HR']\n",
    "\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    filename_train = 'input_data/train.csv'\n",
    "    filename_test = 'input_data/test.csv'\n",
    "    \n",
    "    features = ['AMB', 'CH4', 'CO', 'NMHC', 'NO', 'NO2', 'NOx', 'O3', 'PM10', 'PM2.5', 'RAINFALL', 'RH', 'SO2', 'THC', 'WD_HR', 'WIND_DIR', 'WIND_SPEED', 'WS_HR']\n",
    "    del_features = []\n",
    "\n",
    "    train_set_loss = []\n",
    "    test_set_loss = []\n",
    "\n",
    "    train_set_loss_filtered = []\n",
    "    test_set_loss_filtered = []\n",
    "\n",
    "    X, Y = read_trainData(filename_train)\n",
    "    test_X = read_testData(filename_test)\n",
    "    train_X, valid_X, train_Y, valid_Y = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "        \n",
    "    # Ret = plot_relation(train_X, train_Y, features)\n",
    "    # min_R = 0.3\n",
    "    # for i in range(len(Ret)):\n",
    "    #     if(np.absolute(Ret[i]) < min_R):\n",
    "    #         del_features.append(features[i])\n",
    "    # print(del_features)        \n",
    "    del_features = ['AMB', 'CH4', 'NO', 'O3', 'RAINFALL', 'RH', 'SO2', 'THC', 'WD_HR', 'WIND_DIR', 'WIND_SPEED', 'WS_HR']\n",
    "\n",
    "    # Filtered\n",
    "    train_X = filter(train_X, del_features)\n",
    "    valid_X = filter(valid_X, del_features)\n",
    "    test_X = filter(test_X, del_features)\n",
    "    \n",
    "\n",
    "    model = Linear_Regression()\n",
    "    model.train(train_X, train_Y)\n",
    "\n",
    "    predict_Y = model.predict(valid_X)\n",
    "    valid_loss = RMSE(predict_Y, valid_Y)\n",
    "    \n",
    "    predict_Y = model.predict(train_X)\n",
    "    train_loss = RMSE(predict_Y, train_Y)\n",
    "\n",
    "    predict_result = model.predict(test_X)\n",
    "    Write(predict_result)\n",
    "    # train_set_loss.append(train_loss)\n",
    "    # test_set_loss.append(test_loss)\n",
    "    # test_set_loss = []\n",
    "    # plot_RMSE(valid_loss, train_loss, 'Normal_loss')\n",
    "    print(valid_loss)\n",
    "    print(train_loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
